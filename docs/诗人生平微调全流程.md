1 创建环境



```bash
bash

# 创建环境
conda create --name game_xtuner python=3.10 -y

# 激活环境
conda activate game_xtuner

cd /root/SecondLife/
mkdir /root/SecondLife/game_xtuner && cd /root/SecondLife/game_xtuner

# 拉取0.1.14的版本源码
git clone https://github.com/InternLM/xtuner.git

# 进入源码目录
cd xtuner

# 从源码安装 XTuner
pip install -e '.[all]'
```



2 数据准备

在`data`目录下创建一个json文件`dataset.json`作为本次微调所使用的数据集。

```bash
mkdir /root/SecondLife/data && cd /root/SecondLife/data
```

personal_assistant.json内容如下：复制多次数据增强

```
[
    {
        "conversation": [
            {
                "system": "\u4f60\u662f\u4e00\u4e2a\u5bf9\u540d\u4eba\u751f\u5e73\u7814\u7a76\u9887\u6df1\u7684\u5b66\u8005\u3002\u4f60\u603b\u662f\u53ef\u4ee5\u6839\u636e\u63d0\u95ee\u7ed9\u51fa\u51c6\u786e\u4e14\u8be6\u7ec6\u7684\u7b54\u6848",
                "input": "\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u4f60\u81ea\u5df1",
                "output": "\u60a8\u597d\uff0c\u6211\u662f\u4e00\u4e2a\u5bf9\u540d\u4eba\u751f\u5e73\u7565\u6709\u7814\u7a76\u7684\u5b66\u8005\u5c0f\u5149\uff0c\u6709\u60f3\u8981\u4e86\u89e3\u7684\u540d\u4eba\u90fd\u53ef\u4ee5\u95ee\u6211\u54e6~\uff08\u793a\u4f8b\uff1a\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u674e\u767d\u7684\u751f\u5e73\uff09"
            }
        ]
    },
    {
        "conversation": [
            {
                "system": "\u4f60\u662f\u4e00\u4e2a\u5bf9\u540d\u4eba\u751f\u5e73\u7814\u7a76\u9887\u6df1\u7684\u5b66\u8005\u3002\u4f60\u603b\u662f\u53ef\u4ee5\u6839\u636e\u63d0\u95ee\u7ed9\u51fa\u51c6\u786e\u4e14\u8be6\u7ec6\u7684\u7b54\u6848",
                "input": "\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u4f60\u81ea\u5df1",
                "output": "\u60a8\u597d\uff0c\u6211\u662f\u4e00\u4e2a\u5bf9\u540d\u4eba\u751f\u5e73\u7565\u6709\u7814\u7a76\u7684\u5b66\u8005\u5c0f\u5149\uff0c\u6709\u60f3\u8981\u4e86\u89e3\u7684\u540d\u4eba\u90fd\u53ef\u4ee5\u95ee\u6211\u54e6~\uff08\u793a\u4f8b\uff1a\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u674e\u767d\u7684\u751f\u5e73\uff09"
            }
        ]
    }
]
```



3 配置准备



```
# 下载模型InternLM-chat-7B
mkdir -p /root/SecondLife/game_xtuner/model/Shanghai_AI_Laboratory
cp -r /root/share/model_repos/internlm2-chat-7b /root/SecondLife/game_xtuner/model/Shanghai_AI_Laboratory

# 创建用于存放配置的文件夹config并进入
mkdir /root/SecondLife/game_xtuner/config && cd /root/SecondLife/game_xtuner/config

# 列出所有内置配置
xtuner list-cfg

# 拷贝一个配置文件到当前目录：xtuner copy-cfg ${CONFIG_NAME} ${SAVE_PATH}
xtuner copy-cfg internlm2_chat_7b_qlora_oasst1_e3 .
```

![image-20240129220245708](C:/Users/HeHang/AppData/Roaming/Typora/typora-user-images/image-20240129220245708.png)

修改拷贝后的文件internlm_chat_7b_qlora_oasst1_e3_copy.py，修改下述位置：

```BASH
# PART 1 中
# 预训练模型存放的位置
pretrained_model_name_or_path = '/root/SecondLife/game_xtuner/model/Shanghai_AI_Laboratory/internlm2-chat-7b'

# 微调数据存放的位置
data_path = '/root/SecondLife/data/dataset.json'

# 训练中最大的文本长度
max_length = 1024

# 每一批训练样本的大小
batch_size = 2

# 最大训练轮数
max_epochs = 3

# 验证的频率
evaluation_freq = 500

# 用于评估输出内容的问题（用于评估的问题尽量与数据集的question保持一致）
SYSTEM = '你是一个对名人生平研究颇深的学者。你总是可以根据提问给出准确且详细的答案'
evaluation_inputs = [
    '请介绍一下李白的生平', '请介绍一下杜甫的生平','请介绍一下你自己'
]


# PART 3 中
dataset=dict(type=load_dataset, path='json', data_files=dict(train=data_path))
dataset_map_fn=None
```

PART1 部分

![image-20240129221236705](C:/Users/HeHang/AppData/Roaming/Typora/typora-user-images/image-20240129221236705.png)

PART3 部分

![image-20240110212656150](C:/Users/HeHang/AppData/Roaming/Typora/typora-user-images/image-20240110212656150.png)

4 微调启动

```
apt update -y
apt install tmux -y
# 新建对话
tmux new -s finetune
# Ctrl+B再按D返回bash
tmux attach -s finetune
xtuner train /root/SecondLife/game_xtuner/config/internlm2_chat_7b_qlora_oasst1_e3_copy.py --deepspeed deepspeed_zero2
```





5 参数转换

训练后的pth格式参数转Hugging Face格式

```bash
# 创建用于存放Hugging Face格式参数的hf文件夹
mkdir /root/SecondLife/game_xtuner/config/work_dirs/hf

export MKL_SERVICE_FORCE_INTEL=1

# 配置文件存放的位置
export CONFIG_NAME_OR_PATH=/root/SecondLife/game_xtuner/config/internlm2_chat_7b_qlora_oasst1_e3_copy.py

# 模型训练后得到的pth格式参数存放的位置
export PTH=/root/SecondLife/game_xtuner/config/work_dirs/internlm2_chat_7b_qlora_oasst1_e3_copy/iter_8104.pth

# pth文件转换为Hugging Face格式后参数存放的位置
export SAVE_PATH=/root/SecondLife/game_xtuner/config/work_dirs/hf

# 执行参数转换
xtuner convert pth_to_hf $CONFIG_NAME_OR_PATH $PTH $SAVE_PATH
```

![image-20240130144613908](C:/Users/HeHang/AppData/Roaming/Typora/typora-user-images/image-20240130144613908.png)



6 参数合并



```bash
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER='GNU'

# 原始模型参数存放的位置
export NAME_OR_PATH_TO_LLM=/root/SecondLife/game_xtuner/model/Shanghai_AI_Laboratory/internlm2-chat-7b

# Hugging Face格式参数存放的位置
export NAME_OR_PATH_TO_ADAPTER=/root/SecondLife/game_xtuner/config/work_dirs/hf

# 最终Merge后的参数存放的位置
mkdir /root/SecondLife/game_xtuner/config/work_dirs/hf_merge
export SAVE_PATH=/root/SecondLife/game_xtuner/config/work_dirs/hf_merge

# 执行参数Merge
xtuner convert merge \
    $NAME_OR_PATH_TO_LLM \
    $NAME_OR_PATH_TO_ADAPTER \
    $SAVE_PATH \
    --max-shard-size 2GB
```

![image-20240130145712375](C:/Users/HeHang/AppData/Roaming/Typora/typora-user-images/image-20240130145712375.png)

7 Web部署

```
# 安装依赖
pip install streamlit==1.24.0

# 创建code文件夹用于存放InternLM项目代码
mkdir /root/SecondLife/game_xtuner/code && cd /root/SecondLife/game_xtuner/code
git clone https://github.com/InternLM/InternLM.git

# 修改/root/SecondLife/game_xtuner/code/InternLM/chat/web_demo.py中的模型路径
修改为"/root/SecondLife/game_xtuner/config/work_dirs/hf_merge"

# 运行脚本
cd /root/SecondLife/game_xtuner/code/InternLM
streamlit run /root/SecondLife/game_xtuner/code/InternLM/chat/web_demo.py --server.address 127.0.0.1 --server.port 6006

# powershell
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p [开发机端口号]
```

![image-20240130150741448](C:/Users/HeHang/AppData/Roaming/Typora/typora-user-images/image-20240130150741448.png)

8 最终效果

![image-20240130151219797](C:/Users/HeHang/AppData/Roaming/Typora/typora-user-images/image-20240130151219797.png)